{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "13E6m30HEJbULl8C-WZN8SHqQCvnnNkOQ",
      "authorship_tag": "ABX9TyN0mc9muA7sz4VdJx8lvzMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonbrandberg/patent-landscaping/blob/main/patent-and-research-landscaping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou6mUV-5h0ls"
      },
      "source": [
        "# Setting up with BigQuery\n",
        "[This notebook](https://colab.research.google.com/notebooks/bigquery.ipynb#scrollTo=ONI1Xo0-KtAD) provides a great tutorial on how to set up BigQuery access with Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrKMGvLXqFAe"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zsRdczZfdkb"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmGarMvrglg6"
      },
      "source": [
        "#enter project id\n",
        "project_id = 'patent-classification-313315'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo77YRbFhFc9"
      },
      "source": [
        "#import bigquery\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=project_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8PCkztIKKL9"
      },
      "source": [
        "# Two options:\n",
        "The user can either upload a csv file to their drive that contains the publication numbers of active patents they want to analyze. The file should be formatted with \"publication_number\" as the column name, and the patents should be formatted with \"US-patent_number-patent_kind_code\", ex: \"US-123456-A1\".\n",
        "Alternatively, the user can query patents based on a keyword phrase they provide. It will then return all patent matches that contain that phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0-dG23WLKPL"
      },
      "source": [
        "## Option 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDVGk00ULMn1"
      },
      "source": [
        "# load in dataframe of pub numbers of desired patents to work with \n",
        "# we are working with patents in pharmacology and patient insurance\n",
        "# mount to drive and find file path for appropriate project\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Practicum/sample_pub_numbers.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aWdranRLQRn"
      },
      "source": [
        "dest_dataset = 'desired_publication_numbers'\n",
        "# Upload these to our dataset on BigQuery.\n",
        "ID_table = 'ID_table'\n",
        "full_table_path = '{}.{}'.format(dest_dataset, ID_table)\n",
        "df.to_gbq(full_table_path, project_id, if_exists = \"replace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYNLV_GQLXLX"
      },
      "source": [
        "df = client.query('''\n",
        "#standardSQL\n",
        "\n",
        "WITH P AS (\n",
        "  SELECT \n",
        "  publication_number, \n",
        "  floor(priority_date / 10000) priority_yr\n",
        "  FROM `patents-public-data.patents.publications`\n",
        "  WHERE country_code = 'US'\n",
        "  AND floor(priority_date / 10000) >= 1950\n",
        "  AND country_code = 'US'\n",
        ")\n",
        "\n",
        "SELECT \n",
        "P.publication_number,\n",
        "P.priority_yr,\n",
        "abstracts.text\n",
        "FROM `patents-public-data.patents.publications` as pubs,\n",
        "UNNEST(abstract_localized) as abstracts\n",
        "JOIN P \n",
        "  ON P.publication_number = pubs.publication_number\n",
        "JOIN `patent-classification-313315.desired_publication_numbers.ID_table` my_pubs\n",
        "  ON pubs.publication_number = my_pubs.publication_number\n",
        "WHERE abstracts.language = 'en'\n",
        "''').to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEMLByYPLX30"
      },
      "source": [
        "## Option 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfQm0-FU05pO"
      },
      "source": [
        "df = client.query('''\n",
        "  SELECT * FROM\n",
        "  `patents-public-data.patents.publications` AS patentsdb,\n",
        "  UNNEST(abstract_localized) AS abstract_info\n",
        "  # enter query phrase to search patents for\n",
        "  # in this example, we use the word \"virus\"\n",
        "  WHERE LOWER(abstract_info.text) LIKE '%virus%'\n",
        "    AND patentsdb.country_code = 'US'\n",
        "  ORDER BY patentsdb.priority_date DESC\n",
        "  # enter max number of patents to analyze in results\n",
        "  LIMIT 200\n",
        "''').to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mteXXKwHiN33"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV5LAw3syyhX"
      },
      "source": [
        "abstracts = df[\"abstract_localized\"]\n",
        "abstracts_text = []\n",
        "for i in abstracts:\n",
        "  for j in i:\n",
        "    abstract = j[\"text\"]\n",
        "    abstract = abstract.replace(\"\\n\", \"\")\n",
        "    abstract = abstract.replace(\"&#39;\", \"'\")\n",
        "    abstract = abstract.replace(\"/\", \" or \")\n",
        "    abstract = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", abstract)\n",
        "    if abstract not in abstracts_text:\n",
        "      abstracts_text.append(abstract)\n",
        "    else:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdZ1KJKK0TBD"
      },
      "source": [
        "abstracts_text[0:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxRfhEjfJQ-m"
      },
      "source": [
        "## Optional\n",
        "Here you can add your own idea for a patent abstract and see where it falls within the landscape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPFp1GcOJZXa"
      },
      "source": [
        "#enter text below\n",
        "your_patent = \"Enter your patent here\"\n",
        "abstracts_text.append(your_patent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cc7KiGe6rVZ"
      },
      "source": [
        "# Import BERT Model and Encode Messages\n",
        "Hugging face has [several pretrained BERT models](https://huggingface.co/models). You can use one trained on patents for general use. In our case, one on biomedical data might be more applicable. It is easy to import the different models, so find one that seems to work best for you"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdJm5uFeVTP1"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAPk5XPUVkYh"
      },
      "source": [
        "! pip install -Uq sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk5hgF8dVWcy"
      },
      "source": [
        "import pandas as pd\n",
        "import scipy\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sentence_transformers import models, SentenceTransformer, util\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import util\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# choose a model relevant to this project\n",
        "# \"AI-Growth/PatentSBERTa is a great general patent BERT model\"\n",
        "# for this task, we're using a model trained on biomedical abstracts, which is relevant to our research\n",
        "model = SentenceTransformer('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjG6ZeXW7gUc"
      },
      "source": [
        "#Create Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2H6yFCV6Gcp"
      },
      "source": [
        "# change number below to adjust amount of clusters\n",
        "clusters = 5\n",
        "sentence_embeddings = model.encode(abstracts_text)\n",
        "kmeans = KMeans(n_clusters=clusters).fit(sentence_embeddings)\n",
        "kmeans.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add labels. Run the chunk below based on whether or not you included an original patent"
      ],
      "metadata": {
        "id": "7ehw8iCdsjSH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6OTz7RF1fp"
      },
      "source": [
        "combined_dataset = []\n",
        "# use this if using an original patent\n",
        "for i in range(len(abstracts_text)):\n",
        "  if i == len(abstracts_text)-1:\n",
        "    label = kmeans.labels_[i]\n",
        "    abstract = abstracts_text[i]\n",
        "    source = \"patent original\"\n",
        "    instance = (abstract, source, label)\n",
        "    combined_dataset.append(instance)\n",
        "  else:\n",
        "    label = kmeans.labels_[i]\n",
        "    abstract = abstracts_text[i]\n",
        "    source = \"patent\"\n",
        "    instance = (abstract, source, label)\n",
        "    combined_dataset.append(instance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLfoHM52IIhc"
      },
      "source": [
        "combined_dataset = []\n",
        "# use this if not using an original patent\n",
        "for i in range(len(abstracts_text)):\n",
        "  label = kmeans.labels_[i]\n",
        "  abstract = abstracts_text[i]\n",
        "  source = \"patent\"\n",
        "  instance = (abstract, source, label)\n",
        "  combined_dataset.append(instance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDp8gRqR88oy"
      },
      "source": [
        "# Import New Research and Apply to Existing Clusters\n",
        "Google has many [public datasets](https://cloud.google.com/bigquery/public-data). Feel free to find one relevant to the patents you are landscaping! In this demo, we are using biomedical research on covid-19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOXgG73LDKJJ"
      },
      "source": [
        "#can replace arxiv with other research database\n",
        "research_df = client.query('''\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `bigquery-public-data.breathe.arxiv`\n",
        "''').to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYfKP_UaA2am"
      },
      "source": [
        "research_abstracts = research_df[\"abstract\"]\n",
        "research_abstracts_clean = []\n",
        "#remove \\n that is in the text\n",
        "for i in research_abstracts:\n",
        "  abstract = i.replace(\"\\n\", \"\")\n",
        "  abstract = abstract.replace(\"&#39;\", \"'\")\n",
        "  abstract = abstract.replace(\"/\", \" or \")\n",
        "  abstract = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", abstract)\n",
        "  research_abstracts_clean.append(abstract)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHaEWZVq8WC5"
      },
      "source": [
        "#research_sample = research_abstracts_clean[1:10]\n",
        "research_embeddings = model.encode(research_abstracts_clean)\n",
        "research_labels = kmeans.predict(research_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvIOjzofGlTs"
      },
      "source": [
        "for i in range(len(research_abstracts_clean)):\n",
        "  label = research_labels[i]\n",
        "  abstract = research_abstracts_clean[i]\n",
        "  source = \"research\"\n",
        "  instance = (abstract, source, label)\n",
        "  combined_dataset.append(instance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpKlZzgvHNIP"
      },
      "source": [
        "# Create combined dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ySSF9RHPM6"
      },
      "source": [
        "combined_df = pd.DataFrame(combined_dataset, columns =['Abstract', 'Source', 'Label'])\n",
        "combined_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rziWzsDNMiLs"
      },
      "source": [
        "combined_df[\"Source\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqy16kl6H5IO"
      },
      "source": [
        "#Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwPsely8H6s1"
      },
      "source": [
        "import matplotlib\n",
        "from matplotlib import pylab as plt\n",
        "pd.value_counts(combined_df['Label']).plot.bar()\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Cluster Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JYUn_clE6DA"
      },
      "source": [
        "# Download Created Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rI9SmxaEyXt"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "combined_df.to_csv('patent_and_research_abstracts.csv')\n",
        "files.download('patent_and_research_abstracts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}